Most important things to consider when choosing the input (observation) for the agent:
- Size. It needs to be a fixed size between different templates, which may have different numbers of objects, and not prohibitively large so that compute time is efficient.
- Info. Provides rich enough information to the agent that the agent can make well-educated decisions. 

Secondary Considerations:
- Complexity. How complex is the form of the input? How much does the model have to work out about where the agent is, what the objects are, etc. This also has an impact on whether we can tell what kind of reasoning the agent is performing.
- Philosophy. Why is this an appropriate input? Can we provide an analogous real-world agent with a similar kind of input?



In PHYRE, the models receive a 256x256 rasterization of the environment as input. This totals 65536 inputs, which is a large input space. 

A similar approach is taken in classic RL environments for ATARI video games. A low resolution image is provided. There are also variations which provide the ATARI RAM as input (though I am not sure how large this input is or how it is presented).

In both of these examples, the model input comprehends the entirety of the environment, and the input size is quite large. It is also realistic since humans see a computer screen when they interact with these. 

In summary:
Rasterized image:
SIZE: Bad. We might not have enough compute ourselves
INFO: Perfect. Fully comprehensive
COMP: Okay. Model has to infer things which humans take for granted.
PHIL: Good. Humans see a computer screen for PHYRE and ATARI environments when they interact with them too. (there is an interactive version of PHYRE)

RAM: (not an option for us but can consider as an example) 
SIZE: Bad. This would be a huge input.
INFO: Perfect. All the information about the game is there.
COMP: Bad. RAM is not an intuitive thing, and how would we know what the agent is thinking if we do not understand the input space ourselves?
PHIL: Bad. RAM is not something we can give a human or any kind of real-world agent. 

We could go with the rasterized image, but I want to propose a slight variation. It is often that embodied agents have sensory input. I have experience with this myself in programming evolution simulators. Agents can often detect when something is nearby to it or what direction it is, which is a greatly limited input space, but it is already relativised for the agent! It also mimics what humans have.

I propose that instead of a 256x256 (or similar) image of the whole environment, we take an image of an area in front of the agent. See the diagram. This greatly reduces the size of the input space, which will be better for computation. It will also have good information about the objects which need to be avoided in the future and where it is going to get to its goal. The complexity of this input is good because it is relative to the agent and 